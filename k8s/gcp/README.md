# CounselGPT Kubernetes Manifests (GCP)

## ğŸ“ Folder Structure

```
k8s/gcp/
â”œâ”€â”€ infrastructure/          # Shared infrastructure
â”‚   â”œâ”€â”€ redis-deployment.yaml
â”‚   â”œâ”€â”€ redis-service.yaml
â”‚   â”œâ”€â”€ model-pvc.yaml      # Standard PVC
â”‚   â””â”€â”€ model-pvc-filestore.yaml  # Filestore PVC (ReadWriteMany)
â”‚
â”œâ”€â”€ backend-gpu/             # GPU backend (CUDA-enabled)
â”‚   â”œâ”€â”€ deployment-gpu.yaml
â”‚   â””â”€â”€ service-gpu.yaml
â”‚
â”œâ”€â”€ backend-cpu/             # CPU backend (CPU-only)
â”‚   â”œâ”€â”€ deployment-cpu.yaml
â”‚   â”œâ”€â”€ service-cpu.yaml
â”‚   â””â”€â”€ hpa-cpu.yaml        # Auto-scaling
â”‚
â”œâ”€â”€ router/                  # Intelligent router
â”‚   â””â”€â”€ deployment.yaml     # Router + service + HPA
â”‚
â”œâ”€â”€ ingress/                 # External access
â”‚   â”œâ”€â”€ ingress.yaml
â”‚   â””â”€â”€ managed-certificate.yaml
â”‚
â”œâ”€â”€ apply.sh                 # Deploy everything
â”œâ”€â”€ delete.sh                # Clean up everything
â””â”€â”€ README.md               # This file
```

## ğŸ¯ Components

### Infrastructure
- **Redis**: Cache for semantic caching
- **PVC**: Persistent storage for models (ReadWriteOnce or ReadWriteMany)

### Backend GPU
- **Deployment**: 1 replica with NVIDIA L4 GPU
- **Service**: Internal service for GPU pods
- **Image**: `counselgptapi:gpu-*`
- **Cost**: ~$360/month

### Backend CPU
- **Deployment**: 2-5 replicas (auto-scales)
- **Service**: Internal service for CPU pods
- **HPA**: Scales 2-5 pods based on load
- **Image**: `counselgptapi:cpu-*`
- **Cost**: ~$60-150/month

### Router
- **Deployment**: 2-5 replicas (auto-scales)
- **Service**: `counselgpt-api` (main entry point)
- **Features**: GPU-first routing, circuit breaker, health monitoring
- **Image**: `counselgpt-router:*`
- **Cost**: ~$15-30/month

### Ingress
- **Ingress**: GCP HTTP(S) load balancer
- **Certificate**: Managed SSL certificate
- **Domain**: `*.nip.io` or custom domain