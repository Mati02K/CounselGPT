apiVersion: apps/v1
kind: Deployment
metadata:
  name: counselgpt-api-mthiruma
  namespace: cse239fall2025
spec:
  replicas: 2
  selector:
    matchLabels:
      app: counselgpt-api-mthiruma

  template:
    metadata:
      labels:
        app: counselgpt-api-mthiruma
    spec:

      tolerations:
      - key: "nvidia.com/gpu"
        operator: "Exists"
        effect: "NoSchedule"

      containers:
      - name: counselgpt-api
        image: mathesh0208/counselgptapi:v10
        ports:
        - containerPort: 8000

        resources:
          limits:
            cpu: "2"
            memory: "8Gi"
            nvidia.com/gpu: "1"
          requests:
            cpu: "1"
            memory: "4Gi"
            nvidia.com/gpu: "1"

        env:
        - name: QWEN_MODEL_PATH
          value: "/models/qwen/Qwen2.5-7B-Instruct-Q8_0.gguf"
        - name: QWEN_LORA_PATH
          value: "/models/qwen/legal_lora_adapter_only_25k.gguf"
        - name: QWEN_GPU_LAYERS
          value: "999"

        - name: LLAMA_MODEL_PATH
          value: "/models/llama/llama-2-7b-chat.Q4_K_M.gguf"
        - name: LLAMA_GPU_LAYERS
          value: "35"

        - name: LLM_N_THREADS
          value: "8"

        - name: REDIS_URL
          value: "redis://counselgpt-redis-mthiruma:6379"

        volumeMounts:
        - name: model-volume
          mountPath: /models

      volumes:
      - name: model-volume
        persistentVolumeClaim:
          claimName: counselgpt-models-pvc-mthiruma
