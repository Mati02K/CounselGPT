apiVersion: apps/v1
kind: Deployment
metadata:
  name: counselgpt-api-mthiruma
  namespace: cse239fall2025
spec:
  replicas: 2
  selector:
    matchLabels:
      app: counselgpt-api-mthiruma
  template:
    metadata:
      labels:
        app: counselgpt-api-mthiruma
    spec:

      # Tolerate GPU taints (REQUIRED for Nautilus GPU nodes)
      # TODO do this https://nrp.ai/documentation/userdocs/running/gpu-pods/#requesting-special-gpus 
      tolerations:
      - key: "nvidia.com/gpu"
        operator: "Exists"
        effect: "NoSchedule"

      containers:
      - name: counselgpt-api
        image: mathesh0208/counselgptapi:v7
        ports:
        - containerPort: 8000

        # Request 1 GPU, 8GB RAM
        resources:
          limits:
            cpu: "2"
            memory: "8Gi"
            nvidia.com/gpu: 1          # <-- THIS ENSURES AT LEAST 1 GPU
          requests:
            cpu: "1"
            memory: "4Gi"
            nvidia.com/gpu: 1          # <-- GPU REQUIRED TO SCHEDULE

        env:
        - name: MODEL_PATH
          value: "/models/llama-2-7b-chat.Q4_K_M.gguf"
        - name: REDIS_URL
          value: "redis://counselgpt-redis-mthiruma:6379"

        volumeMounts:
        - name: model-volume
          mountPath: /models

      volumes:
      - name: model-volume
        persistentVolumeClaim:
          claimName: counselgpt-models-pvc-mthiruma
