{
  "title": "CounselGPT - Clean LLM Metrics Dashboard",
  "timezone": "browser",
  "schemaVersion": 35,
  "version": 2,
  "tags": ["counselgpt", "llm", "inference"],
  "panels": [
    {
      "id": 1,
      "type": "stat",
      "title": "Average Inference Latency (5m)",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 8, "x": 0, "y": 0 },
      "targets": [
        {
          "expr": "rate(inference_duration_seconds_sum[5m]) / clamp_min(rate(inference_duration_seconds_count[5m]), 1)"
        }
      ]
    },
    {
      "id": 2,
      "type": "timeseries",
      "title": "P50 / P90 / P99 Latency (seconds)",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 8, "x": 8, "y": 0 },
      "targets": [
        {
          "expr": "histogram_quantile(0.5, sum(rate(inference_duration_seconds_bucket[5m])) by (le))",
          "legendFormat": "P50"
        },
        {
          "expr": "histogram_quantile(0.9, sum(rate(inference_duration_seconds_bucket[5m])) by (le))",
          "legendFormat": "P90"
        },
        {
          "expr": "histogram_quantile(0.99, sum(rate(inference_duration_seconds_bucket[5m])) by (le))",
          "legendFormat": "P99"
        }
      ]
    },
    {
      "id": 3,
      "type": "stat",
      "title": "Total Tokens Generated (All Time)",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 8, "x": 16, "y": 0 },
      "targets": [
        {
          "expr": "sum(tokens_generated_total)"
        }
      ]
    },
    {
      "id": 4,
      "type": "timeseries",
      "title": "Tokens Generated Per Second",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 8, "x": 0, "y": 8 },
      "targets": [
        {
          "expr": "sum(rate(tokens_generated_total[1m]))",
          "legendFormat": "tokens/sec"
        }
      ]
    },
    {
      "id": 30,
      "type": "stat",
      "title": "Total Tokens Generated (Last 5 Minutes)",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 8, "x": 8, "y": 8 },
      "targets": [
        {
          "expr": "sum(rate(tokens_generated_total[5m])) * 300"
        }
      ]
    },
    {
      "id": 12,
      "type": "stat",
      "title": "Average Tokens Per Request (5m)",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 8, "x": 16, "y": 8 },
      "targets": [
        {
          "expr": "sum(rate(tokens_generated_total[5m])) / clamp_min(sum(rate(http_requests_total[5m])), 1)"
        }
      ]
    },
    {
      "id": 5,
      "type": "gauge",
      "title": "Cache Hit Ratio (5m)",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 8, "x": 0, "y": 16 },
      "options": { "minValue": 0, "maxValue": 1 },
      "targets": [
        {
          "expr": "sum(rate(cache_hits_total[5m])) / clamp_min(sum(rate(cache_hits_total[5m])) + sum(rate(cache_misses_total[5m])), 1)"
        }
      ]
    },
    {
      "id": 6,
      "type": "timeseries",
      "title": "Cache Hits vs Misses",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 8, "x": 8, "y": 16 },
      "targets": [
        { "expr": "sum(rate(cache_hits_total[1m]))", "legendFormat": "hits/sec" },
        { "expr": "sum(rate(cache_misses_total[1m]))", "legendFormat": "misses/sec" }
      ]
    },
    {
      "id": 7,
      "type": "timeseries",
      "title": "HTTP Requests Per Second",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 8, "x": 16, "y": 16 },
      "targets": [
        {
          "expr": "sum(rate(http_requests_total[1m]))",
          "legendFormat": "req/sec"
        }
      ]
    },
    {
      "id": 8,
      "type": "timeseries",
      "title": "HTTP Status Codes",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 8, "x": 0, "y": 24 },
      "targets": [
        {
          "expr": "sum(rate(http_requests_total[1m])) by (status)",
          "legendFormat": "status {{status}}"
        }
      ]
    },
    {
      "id": 9,
      "type": "timeseries",
      "title": "CPU Usage Per Pod (API only)",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 8, "x": 8, "y": 24 },
      "targets": [
        {
          "expr": "sum(rate(process_cpu_seconds_total{job=\"counselgpt-api\"}[1m])) by (instance)",
          "legendFormat": "{{instance}}"
        }
      ]
    },
    {
      "id": 10,
      "type": "timeseries",
      "title": "Memory Usage (RSS bytes, API only)",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 8, "x": 16, "y": 24 },
      "targets": [
        {
          "expr": "process_resident_memory_bytes{job=\"counselgpt-api\"}",
          "legendFormat": "{{instance}}"
        }
      ]
    },
    {
      "id": 11,
      "type": "timeseries",
      "title": "In-Progress HTTP Requests",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 8, "x": 0, "y": 32 },
      "targets": [
        {
          "expr": "sum(http_requests_inprogress) by (handler)",
          "legendFormat": "{{handler}}"
        }
      ]
    },
    {
      "id": 20,
      "type": "timeseries",
      "title": "GC Collections Per Second",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 8, "x": 8, "y": 32 },
      "targets": [
        {
          "expr": "rate(python_gc_collections_total[1m])",
          "legendFormat": "gen {{generation}}"
        }
      ]
    },
    {
      "id": 21,
      "type": "timeseries",
      "title": "Open File Descriptors",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 8, "x": 16, "y": 32 },
      "targets": [
        {
          "expr": "process_open_fds",
          "legendFormat": "{{instance}}"
        }
      ]
    },
    {
      "id": 22,
      "type": "timeseries",
      "title": "Virtual Memory Usage",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 8, "x": 0, "y": 40 },
      "targets": [
        {
          "expr": "process_virtual_memory_bytes",
          "legendFormat": "{{instance}}"
        }
      ]
    }
  ]
}
