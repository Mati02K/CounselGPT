{
  "title": "CounselGPT - Clean LLM Metrics Dashboard",
  "timezone": "browser",
  "schemaVersion": 35,
  "version": 1,
  "tags": ["counselgpt", "llm", "inference"],
  "panels": [
    {
      "id": 1,
      "type": "stat",
      "title": "Average Inference Latency (5m)",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 8, "x": 0, "y": 0 },
      "targets": [
        {
          "expr": "rate(inference_duration_seconds_sum[5m]) / clamp_min(rate(inference_duration_seconds_count[5m]), 1)",
          "legendFormat": ""
        }
      ]
    },
    {
      "id": 2,
      "type": "timeseries",
      "title": "P50 / P90 / P99 Latency (seconds)",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 8, "x": 8, "y": 0 },
      "targets": [
        {
          "expr": "histogram_quantile(0.5, sum(rate(inference_duration_seconds_bucket[5m])) by (le))",
          "legendFormat": "P50"
        },
        {
          "expr": "histogram_quantile(0.9, sum(rate(inference_duration_seconds_bucket[5m])) by (le))",
          "legendFormat": "P90"
        },
        {
          "expr": "histogram_quantile(0.99, sum(rate(inference_duration_seconds_bucket[5m])) by (le))",
          "legendFormat": "P99"
        }
      ]
    },
    {
      "id": 3,
      "type": "stat",
      "title": "Total Tokens Generated",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 8, "x": 16, "y": 0 },
      "targets": [
        {
          "expr": "sum(tokens_generated_total)",
          "legendFormat": ""
        }
      ]
    },
    {
      "id": 4,
      "type": "timeseries",
      "title": "Tokens Generated Per Second",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 8, "x": 0, "y": 8 },
      "targets": [
        {
          "expr": "sum(rate(tokens_generated_total[1m]))",
          "legendFormat": "tokens/sec"
        }
      ]
    },
    {
      "id": 5,
      "type": "gauge",
      "title": "Cache Hit Ratio (5m)",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 8, "x": 8, "y": 8 },
      "options": {
        "minValue": 0,
        "maxValue": 1
      },
      "targets": [
        {
          "expr": "sum(rate(cache_hits_total[5m])) / clamp_min(sum(rate(cache_hits_total[5m])) + sum(rate(cache_misses_total[5m])), 1)",
          "legendFormat": ""
        }
      ]
    },
    {
      "id": 6,
      "type": "timeseries",
      "title": "Cache Hits vs Misses",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 8, "x": 16, "y": 8 },
      "targets": [
        {
          "expr": "sum(rate(cache_hits_total[1m]))",
          "legendFormat": "hits/sec"
        },
        {
          "expr": "sum(rate(cache_misses_total[1m]))",
          "legendFormat": "misses/sec"
        }
      ]
    },
    {
      "id": 7,
      "type": "timeseries",
      "title": "HTTP Requests Per Second",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 16 },
      "targets": [
        {
          "expr": "sum(rate(http_requests_total[1m]))",
          "legendFormat": "req/sec"
        }
      ]
    },
    {
      "id": 8,
      "type": "timeseries",
      "title": "HTTP Status Codes",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 16 },
      "targets": [
        {
          "expr": "sum(rate(http_requests_total[1m])) by (status)",
          "legendFormat": "status {{status}}"
        }
      ]
    },
    {
      "id": 9,
      "type": "timeseries",
      "title": "CPU Usage Per Pod (API only)",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 24 },
      "targets": [
        {
          "expr": "sum(rate(process_cpu_seconds_total{job=\"counselgpt-api\"}[1m])) by (instance)",
          "legendFormat": "{{instance}}"
        }
      ]
    },
    {
      "id": 10,
      "type": "timeseries",
      "title": "Memory Usage (RSS bytes, API only)",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 24 },
      "targets": [
        {
          "expr": "process_resident_memory_bytes{job=\"counselgpt-api\"}",
          "legendFormat": "{{instance}}"
        }
      ]
    },
    {
      "id": 11,
      "type": "timeseries",
      "title": "In-Progress HTTP Requests",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 12, "x": 0, "y": 32 },
      "targets": [
        {
          "expr": "sum(http_requests_inprogress) by (handler)",
          "legendFormat": "{{handler}}"
        }
      ]
    },
    {
      "id": 12,
      "type": "stat",
      "title": "Average Tokens Per Request (5m)",
      "datasource": "prometheus",
      "gridPos": { "h": 8, "w": 12, "x": 12, "y": 32 },
      "targets": [
        {
          "expr": "sum(rate(tokens_generated_total[5m])) / clamp_min(sum(rate(http_requests_total[5m])), 1)",
          "legendFormat": ""
        }
      ]
    }
  ]
}
