# CPU-only Dockerfile (no CUDA dependencies)
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    cmake \
    git \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements
COPY requirements.txt .

# Install Python packages (CPU-only llama-cpp-python)
RUN pip install --no-cache-dir -r requirements.txt

# Install llama-cpp-python with CPU-only support
RUN CMAKE_ARGS="-DLLAMA_BLAS=ON -DLLAMA_BLAS_VENDOR=OpenBLAS" \
    pip install --no-cache-dir --force-reinstall llama-cpp-python

# Copy application code
COPY app.py cache.py metrics.py modelclass.py prompt.py ./
COPY llm/ ./llm/

# Create models directory
RUN mkdir -p /models/qwen /models/llama

# Non-root user
RUN useradd -m -u 1000 appuser && \
    chown -R appuser:appuser /app /models
USER appuser

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
  CMD python -c "import requests; requests.get('http://localhost:8000/health', timeout=5)"

# Run with Gunicorn
CMD ["gunicorn", "app:app", \
     "--bind", "0.0.0.0:8000", \
     "--workers", "2", \
     "--worker-class", "uvicorn.workers.UvicornWorker", \
     "--timeout", "120", \
     "--log-level", "info"]

