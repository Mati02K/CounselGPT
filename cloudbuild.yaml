options:
  logging: CLOUD_LOGGING_ONLY
  machineType: 'E2_HIGHCPU_8'  # Faster builds

substitutions:
  _IMAGE_PATH: "us-central1-docker.pkg.dev/applied-syntax-479504-j6/counselgpt-image/counselgptapi"
  _ROUTER_IMAGE: "us-central1-docker.pkg.dev/applied-syntax-479504-j6/counselgpt-image/counselgpt-router"
  _EMBEDDING_IMAGE: "us-central1-docker.pkg.dev/applied-syntax-479504-j6/counselgpt-image/semantic-embeddings"

steps:
  # ========================================
  # 0. CACHE WARMUP PHASE
  # ========================================
  # Pull latest images to use as cache for faster builds
  - name: 'gcr.io/cloud-builders/docker'
    id: 'pull-cache'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        docker pull ${_IMAGE_PATH}:gpu-latest || true
        docker pull ${_IMAGE_PATH}:cpu-latest || true
        docker pull ${_ROUTER_IMAGE}:latest || true
        docker pull ${_EMBEDDING_IMAGE}:latest || true
    waitFor: ['-']

  # ========================================
  # 1. PARALLEL BUILD PHASE
  # ========================================
  
  # 1a. Build GPU image (CUDA-enabled)
  - name: 'gcr.io/cloud-builders/docker'
    id: 'build-gpu'
    waitFor: ['pull-cache']  # Wait for cache to be available
    args:
      - 'build'
      - '-f'
      - 'backend/api/Dockerfile.gpu'
      - '-t'
      - '${_IMAGE_PATH}:gpu-${SHORT_SHA}'
      - '-t'
      - '${_IMAGE_PATH}:gpu-latest'
      - '--cache-from'
      - '${_IMAGE_PATH}:gpu-latest'
      - 'backend/api'

  # 1b. Build CPU image (CPU-only)
  - name: 'gcr.io/cloud-builders/docker'
    id: 'build-cpu'
    waitFor: ['pull-cache']
    args:
      - 'build'
      - '-f'
      - 'backend/api/Dockerfile.cpu'
      - '-t'
      - '${_IMAGE_PATH}:cpu-${SHORT_SHA}'
      - '-t'
      - '${_IMAGE_PATH}:cpu-latest'
      - '--cache-from'
      - '${_IMAGE_PATH}:cpu-latest'
      - 'backend/api'

  # 1c. Build Router image
  - name: 'gcr.io/cloud-builders/docker'
    id: 'build-router'
    waitFor: ['pull-cache']
    args:
      - 'build'
      - '-f'
      - 'backend/router/Dockerfile.router'
      - '-t'
      - '${_ROUTER_IMAGE}:${SHORT_SHA}'
      - '-t'
      - '${_ROUTER_IMAGE}:latest'
      - '--cache-from'
      - '${_ROUTER_IMAGE}:latest'
      - 'backend/router'

  # 1d. Build Embeddings image
  - name: 'gcr.io/cloud-builders/docker'
    id: 'build-embeddings'
    waitFor: ['pull-cache']
    args:
      - 'build'
      - '-f'
      - 'backend/semantic-cache/Dockerfile.semantic'
      - '-t'
      - '${_EMBEDDING_IMAGE}:${SHORT_SHA}'
      - '-t'
      - '${_EMBEDDING_IMAGE}:latest'
      - '--cache-from'
      - '${_EMBEDDING_IMAGE}:latest'
      - 'backend/semantic-cache'

  # ========================================
  # 2. PUSH PHASE (after builds complete)
  # ========================================
  
  # 2a. Push GPU image
  - name: 'gcr.io/cloud-builders/docker'
    id: 'push-gpu'
    waitFor: ['build-gpu']
    args:
      - 'push'
      - '${_IMAGE_PATH}:gpu-${SHORT_SHA}'

  # 2b. Push GPU latest tag (parallel to gpu-sha push)
  - name: 'gcr.io/cloud-builders/docker'
    id: 'push-gpu-latest'
    waitFor: ['build-gpu']
    args:
      - 'push'
      - '${_IMAGE_PATH}:gpu-latest'

  # 2c. Push CPU image
  - name: 'gcr.io/cloud-builders/docker'
    id: 'push-cpu'
    waitFor: ['build-cpu']
    args:
      - 'push'
      - '${_IMAGE_PATH}:cpu-${SHORT_SHA}'

  # 2d. Push CPU latest tag (parallel to cpu-sha push)
  - name: 'gcr.io/cloud-builders/docker'
    id: 'push-cpu-latest'
    waitFor: ['build-cpu']
    args:
      - 'push'
      - '${_IMAGE_PATH}:cpu-latest'

  # 2e. Push Router image
  - name: 'gcr.io/cloud-builders/docker'
    id: 'push-router'
    waitFor: ['build-router']
    args:
      - 'push'
      - '${_ROUTER_IMAGE}:${SHORT_SHA}'

  # 2f. Push Router latest tag (parallel to router-sha push)
  - name: 'gcr.io/cloud-builders/docker'
    id: 'push-router-latest'
    waitFor: ['build-router']
    args:
      - 'push'
      - '${_ROUTER_IMAGE}:latest'

  # 2g. Push Embeddings image
  - name: 'gcr.io/cloud-builders/docker'
    id: 'push-embeddings'
    waitFor: ['build-embeddings']
    args:
      - 'push'
      - '${_EMBEDDING_IMAGE}:${SHORT_SHA}'

  # 2h. Push Embeddings latest tag (parallel to embeddings-sha push)
  - name: 'gcr.io/cloud-builders/docker'
    id: 'push-embeddings-latest'
    waitFor: ['build-embeddings']
    args:
      - 'push'
      - '${_EMBEDDING_IMAGE}:latest'

  # ========================================
  # 3. DEPLOY PHASE (after all images pushed)
  # ========================================
  
  # 3a. Set kube credentials
  - name: 'gcr.io/cloud-builders/gcloud'
    id: 'get-credentials'
    waitFor: ['push-gpu', 'push-gpu-latest', 'push-cpu', 'push-cpu-latest', 'push-router', 'push-router-latest', 'push-embeddings-latest', 'push-embeddings']
    args:
      - 'container'
      - 'clusters'
      - 'get-credentials'
      - 'counselgpt-cluster'
      - '--zone'
      - 'us-west1-a'

  # 3b. Deploy to Kubernetes
  - name: "gcr.io/cloud-builders/kubectl"
    id: 'deploy'
    waitFor: ['get-credentials']
    entrypoint: bash
    args:
      - "-c"
      - |
        echo "üöÄ Deploying CounselGPT multi-tier stack..."
        
        # Update image references
        sed -i "s|REPLACE_IMAGE|${_IMAGE_PATH}:gpu-${SHORT_SHA}|g" k8s/gcp/api-gpu/deployment-gpu.yaml
        sed -i "s|REPLACE_IMAGE|${_IMAGE_PATH}:cpu-${SHORT_SHA}|g" k8s/gcp/api-cpu/deployment-cpu.yaml
        sed -i "s|REPLACE_ROUTER_IMAGE|${_ROUTER_IMAGE}:${SHORT_SHA}|g" k8s/gcp/router/deployment.yaml
        sed -i "s|REPLACE_EMBEDDING_IMAGE|${_EMBEDDING_IMAGE}:${SHORT_SHA}|g" k8s/gcp/semantic-cache/deployment.yaml
        
        # Apply infrastructure (PVC for models)
        echo "üì¶ Applying infrastructure..."
        kubectl apply -f k8s/gcp/infrastructure/
        
        # Apply semantic cache (Redis Stack + Embeddings)
        echo "üóÑÔ∏è  Deploying semantic cache..."
        kubectl apply -f k8s/gcp/semantic-cache/
        
        # Apply GPU backend (deployment + service)
        echo "üéÆ Deploying GPU backend..."
        kubectl apply -f k8s/gcp/api-gpu/
        
        # Apply CPU backend (deployment + service + HPA)
        echo "üíª Deploying CPU backend..."
        kubectl apply -f k8s/gcp/api-cpu/
        
        # Apply router (creates main counselgpt-api service)
        echo "üß≠ Deploying router..."
        kubectl apply -f k8s/gcp/router/
        
        # Apply monitoring (Prometheus + Grafana)
        echo "üìä Deploying monitoring..."
        kubectl apply -f k8s/gcp/monitoring/
        
        # Apply ingress (external access + SSL)
        echo "üåê Applying ingress..."
        kubectl apply -f k8s/gcp/ingress/
        
        # Wait for rollouts (Removed redundant restarts)
        echo "‚è≥ Waiting for rollouts to complete..."
        kubectl rollout status deployment/counselgpt-api-gpu --timeout=5m
        kubectl rollout status deployment/counselgpt-api-cpu --timeout=5m
        kubectl rollout status deployment/counselgpt-router --timeout=3m
        
        echo "‚úÖ Deployment complete!"
        echo ""
        echo "üìã Status:"
        kubectl get pods -l app=counselgpt-api
        kubectl get pods -l app=counselgpt-router
        kubectl get svc counselgpt-api

# Register all images
images:
  - '${_IMAGE_PATH}:gpu-${SHORT_SHA}'
  - '${_IMAGE_PATH}:gpu-latest'
  - '${_IMAGE_PATH}:cpu-${SHORT_SHA}'
  - '${_IMAGE_PATH}:cpu-latest'
  - '${_ROUTER_IMAGE}:${SHORT_SHA}'
  - '${_ROUTER_IMAGE}:latest'
  - '${_EMBEDDING_IMAGE}:${SHORT_SHA}'
  - '${_EMBEDDING_IMAGE}:latest'
