# CPU-only Dockerfile (no CUDA dependencies)
FROM python:3.11-slim

WORKDIR /app

# 1. Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    cmake \
    git \
    && rm -rf /var/lib/apt/lists/*

# 2. Install uv
COPY --from=ghcr.io/astral-sh/uv:latest /uv /bin/uv

# 3. Create venv
ENV VIRTUAL_ENV=/opt/venv
RUN uv venv $VIRTUAL_ENV
ENV PATH="$VIRTUAL_ENV/bin:$PATH"

# 4. Install Python dependencies
COPY requirements.txt .
RUN uv pip install --no-cache -r requirements.txt

# 5. Install llama-cpp-python with CPU-only support
# We force reinstall to ensure it picks up the CMAKE_ARGS for OpenBLAS
RUN CMAKE_ARGS="-DLLAMA_BLAS=ON -DLLAMA_BLAS_VENDOR=OpenBLAS" \
    uv pip install --no-cache --force-reinstall llama-cpp-python

# 6. Copy application code
COPY app.py cache.py metrics.py modelclass.py prompt.py ./
COPY llm/ ./llm/

# 7. Create models directory
RUN mkdir -p /models/qwen /models/llama

# 8. Non-root user
RUN useradd -m -u 1000 appuser && \
    chown -R appuser:appuser /app /models
USER appuser

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
  CMD python -c "import requests; requests.get('http://localhost:8000/health', timeout=5)"

# Run with Gunicorn
CMD ["gunicorn", "app:app", \
     "--bind", "0.0.0.0:8000", \
     "--workers", "2", \
     "--worker-class", "uvicorn.workers.UvicornWorker", \
     "--timeout", "120", \
     "--log-level", "info"]
